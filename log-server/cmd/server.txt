package main

import (
	"database/sql"
	"fmt"
	"net/http"
	"sync"
	"time"

	"github.com/gin-gonic/gin"
	_ "github.com/mattn/go-sqlite3"
)

// Log structure
type Log struct {
	Level      string    `json:"level"`
	Message    string    `json:"message"`
	ResourceID string    `json:"resourceId"`
	Timestamp  time.Time `json:"timestamp"`
	TraceID    string    `json:"traceId"`
	SpanID     string    `json:"spanId"`
	Commit     string    `json:"commit"`
	Metadata   Metadata  `json:"metadata"`
}

// Metadata structure
type Metadata struct {
	ParentResourceID string `json:"parentResourceId"`
}

// LogStore is a SQLite-backed store for logs
type LogStore struct {
	db       *sql.DB
	mu       sync.RWMutex
	workerWG sync.WaitGroup
}

// Setup ingestion & query routes
func setupRouter(logStore *LogStore) *gin.Engine {
	r := gin.Default()

	r.POST("/", func(c *gin.Context) {
		var log Log
		if err := c.BindJSON(&log); err != nil {
			c.JSON(http.StatusBadRequest, gin.H{"error": "Bad Request"})
			return
		}

		// Handle large volumes of concurrent logs by using a worker pool
		logStore.workerWG.Add(1)
		go func(log Log) {
			defer logStore.workerWG.Done()

			logStore.mu.Lock()
			defer logStore.mu.Unlock()

			_, err := logStore.db.Exec(
				"INSERT INTO logs (level, message, resourceId, timestamp, traceId, spanId, commit_hash, parentResourceId) VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
				log.Level, log.Message, log.ResourceID, log.Timestamp, log.TraceID, log.SpanID, log.Commit, log.Metadata.ParentResourceID,
			)
			if err != nil {
				fmt.Println("Error inserting log into database:", err)
			}
		}(log)

		response := gin.H{
			"status": "success",
		}

		c.JSON(http.StatusAccepted, response)
	})

	r.GET("/logs-count", func(c *gin.Context) {
		logStore.mu.RLock()
		defer logStore.mu.RUnlock()

		var count int
		err := logStore.db.QueryRow("SELECT COUNT(*) FROM logs").Scan(&count)
		if err != nil {
			fmt.Println("Error querying logs count:", err)
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Internal Server Error"})
			return
		}

		c.JSON(http.StatusOK, gin.H{"count": count})
	})

	r.GET("/query", func(c *gin.Context) {
		// Implement your query logic here

		// For example, you can retrieve logs based on a specific field filter
		fieldValue := c.Query("fieldValue")
		if fieldValue != "" {
			logStore.mu.RLock()
			defer logStore.mu.RUnlock()

			rows, err := logStore.db.Query("SELECT * FROM logs WHERE level = ? OR resourceId = ?", fieldValue, fieldValue)
			if err != nil {
				fmt.Println("Error querying logs:", err)
				c.JSON(http.StatusInternalServerError, gin.H{"error": "Internal Server Error"})
				return
			}
			defer rows.Close()

			// Implement your response logic here
			// For now, let's just return the logs with the specified field value
			var result []Log
			for rows.Next() {
				var log Log
				err := rows.Scan(
					&log.Level, &log.Message, &log.ResourceID, &log.Timestamp,
					&log.TraceID, &log.SpanID, &log.Commit, &log.Metadata.ParentResourceID,
				)
				if err != nil {
					fmt.Println("Error scanning log row:", err)
					continue
				}
				result = append(result, log)
			}
			c.JSON(http.StatusOK, result)
		} else {
			c.Status(http.StatusOK)
		}
	})

	return r
}

func main() {
	// Open SQLite database
	db, err := sql.Open("sqlite3", "./logs.db")
	if err != nil {
		fmt.Println("Error opening database:", err)
		return
	}
	defer db.Close()

	// Create logs table if not exists
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS logs (
			level TEXT,
			message TEXT,
			resourceId TEXT,
			timestamp DATETIME,
			traceId TEXT,
			spanId TEXT,
			commit_hash TEXT,
			parentResourceId TEXT
		);
	`)
	if err != nil {
		fmt.Println("Error creating logs table:", err)
		return
	}

	logStore := &LogStore{db: db}

	r := setupRouter(logStore)

	fmt.Println("Starting server on :3000...")
	if err := r.Run(":3000"); err != nil {
		fmt.Println("Error starting server:", err)
	}

	fmt.Println("Bye !!!")

	// Wait for all workers to finish before exiting
	logStore.workerWG.Wait()

	select {}
}
